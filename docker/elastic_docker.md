The vm_max_map_count kernel setting needs to be set to at least 262144 for production use. Depending on your platform:

Linux

The vm_map_max_count setting should be set permanently in /etc/sysctl.conf:

$ grep vm.max_map_count /etc/sysctl.conf
vm.max_map_count=262144
To apply the setting on a live system type: sysctl -w vm.max_map_count=262144



###########################################################################################################################


A data volume is a specially-designated directory within one or more containers that bypasses the Union File System. Data volumes provide several useful features for persistent or shared data:

Volumes are initialized when a container is created. If the container’s base image contains data at the specified mount point, that existing data is copied into the new volume upon volume initialization. (Note that this does not apply when mounting a host directory.)
Data volumes can be shared and reused among containers.
Changes to a data volume are made directly.
Changes to a data volume will not be included when you update an image.
Data volumes persist even if the container itself is deleted.
Data volumes are designed to persist data, independent of the container’s lifecycle. Docker therefore never automatically deletes volumes when you remove a container, nor will it “garbage collect” volumes that are no longer referenced by a container.

###########################################################################################################################

One way to configure Kibana on Docker is to provide kibana.yml via bind-mounting. With docker-compose, the bind-mount can be specified like this:

Kibana Configuration Settings

server.port:
Default: 5601 Kibana is served by a back end server. This setting specifies the port to use.

server.host:
Default: "localhost" This setting specifies the host of the back end server.

server.basePath:
Enables you to specify a path to mount Kibana at if you are running behind a proxy. This only affects the URLs generated by Kibana, your proxy is expected to remove the basePath value before forwarding requests to Kibana. This setting cannot end in a slash (/).

server.maxPayloadBytes:
Default: 1048576 The maximum payload size in bytes for incoming server requests.

server.name:
Default: "your-hostname" A human-readable display name that identifies this Kibana instance.

server.defaultRoute:
Default: "/app/kibana" This setting specifies the default route when opening Kibana. You can use this setting to modify the landing page when opening Kibana.

elasticsearch.url:
Default: "http://localhost:9200" The URL of the Elasticsearch instance to use for all your queries.

elasticsearch.preserveHost:
Default: true When this setting’s value is true Kibana uses the hostname specified in the server.host setting. When the value of this setting is false, Kibana uses the hostname of the host that connects to this Kibana instance.

kibana.index:
Default: ".kibana" Kibana uses an index in Elasticsearch to store saved searches, visualizations and dashboards. Kibana creates a new index if the index doesn’t already exist.

kibana.defaultAppId:
Default: "discover" The default application to load.

tilemap.url:
The URL to the tile service that Kibana uses to display map tiles in tilemap visualizations. By default, Kibana reads this url from an external metadata service, but users can still override this parameter to use their own Tile Map Service. For example: "https://tiles.elastic.co/v2/default/{z}/{x}/{y}.png?elastic_tile_service_tos=agree&my_app_name=kibana"

tilemap.options.minZoom:
Default: 1 The minimum zoom level.

tilemap.options.maxZoom:
Default: 10 The maximum zoom level.

tilemap.options.attribution:
Default: "© [Elastic Tile Service](https://www.elastic.co/elastic-tile-service)" The map attribution string.

tilemap.options.subdomains:
An array of subdomains used by the tile service. Specify the position of the subdomain the URL with the token {s}.

elasticsearch.username: and elasticsearch.password:
If your Elasticsearch is protected with basic authentication, these settings provide the username and password that the Kibana server uses to perform maintenance on the Kibana index at startup. Your Kibana users still need to authenticate with Elasticsearch, which is proxied through the Kibana server.

server.ssl.enabled
Default: "false" Enables SSL for outgoing requests from the Kibana server to the browser. When set to true, server.ssl.certificate and server.ssl.key are required

server.ssl.certificate: and server.ssl.key:
Paths to the PEM-format SSL certificate and SSL key files, respectively.

server.ssl.keyPassphrase
The passphrase that will be used to decrypt the private key. This value is optional as the key may not be encrypted.

server.ssl.certificateAuthorities
List of paths to PEM encoded certificate files that should be trusted.

server.ssl.supportedProtocols
Default: TLSv1, TLSv1.1, TLSv1.2 Supported protocols with versions. Valid protocols: TLSv1, TLSv1.1, TLSv1.2

server.ssl.cipherSuites
Default: ECDHE-RSA-AES128-GCM-SHA256, ECDHE-ECDSA-AES128-GCM-SHA256, ECDHE-RSA-AES256-GCM-SHA384, ECDHE-ECDSA-AES256-GCM-SHA384, DHE-RSA-AES128-GCM-SHA256, ECDHE-RSA-AES128-SHA256, DHE-RSA-AES128-SHA256, ECDHE-RSA-AES256-SHA384, DHE-RSA-AES256-SHA384, ECDHE-RSA-AES256-SHA256, DHE-RSA-AES256-SHA256, HIGH,!aNULL, !eNULL, !EXPORT, !DES, !RC4, !MD5, !PSK, !SRP, !CAMELLIA. Details on the format, and the valid options, are available via the [OpenSSL cipher list format documentation](https://www.openssl.org/docs/man1.0.2/apps/ciphers.html#CIPHER-LIST-FORMAT)

elasticsearch.ssl.certificate: and elasticsearch.ssl.key:
Optional settings that provide the paths to the PEM-format SSL certificate and key files. These files validate that your Elasticsearch backend uses the same key files.

elasticsearch.ssl.keyPassphrase
The passphrase that will be used to decrypt the private key. This value is optional as the key may not be encrypted.

elasticsearch.ssl.certificateAuthorities:
Optional setting that enables you to specify a list of paths to the PEM file for the certificate authority for your Elasticsearch instance.

elasticsearch.ssl.verificationMode:
Default: full Controls the verification of certificates. Valid values are none, certificate, and full. full performs hostname verification, and certificate does not.

elasticsearch.pingTimeout:
Default: the value of the elasticsearch.requestTimeout setting Time in milliseconds to wait for Elasticsearch to respond to pings.

elasticsearch.requestTimeout:
Default: 30000 Time in milliseconds to wait for responses from the back end or Elasticsearch. This value must be a positive integer.

elasticsearch.requestHeadersWhitelist:
Default: [ 'authorization' ] List of Kibana client-side headers to send to Elasticsearch. To send no client-side headers, set this value to [] (an empty list).

elasticsearch.customHeaders:
Default: {} Header names and values to send to Elasticsearch. Any custom headers cannot be overwritten by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration.

elasticsearch.shardTimeout:
Default: 0 Time in milliseconds for Elasticsearch to wait for responses from shards. Set to 0 to disable.

elasticsearch.startupTimeout:
Default: 5000 Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying.

pid.file:
Specifies the path where Kibana creates the process ID file.

logging.dest:
Default: stdout Enables you specify a file where Kibana stores log output.

logging.silent:
Default: false Set the value of this setting to true to suppress all logging output.

logging.quiet:
Default: false Set the value of this setting to true to suppress all logging output other than error messages.

logging.verbose
Default: false Set the value of this setting to true to log all events, including system usage information and all requests.

ops.interval
Default: 5000 Set the interval in milliseconds to sample system and process performance metrics. The minimum value is 100.

status.allowAnonymous
Default: false If authentication is enabled, setting this to true allows unauthenticated users to access the Kibana server status API and status page.

cpu.cgroup.path.override
Override for cgroup cpu path when mounted in manner that is inconsistent with /proc/self/cgroup

cpuacct.cgroup.path.override
Override for cgroup cpuacct path when mounted in manner that is inconsistent with /proc/self/cgroup

console.enabled
Default: true Set to false to disable Console. Toggling this will cause the server to regenerate assets on the next startup, which may cause a delay before pages start being served.

elasticsearch.tribe.url:
Optional URL of the Elasticsearch tribe instance to use for all your queries.

elasticsearch.tribe.username: and elasticsearch.tribe.password:
If your Elasticsearch is protected with basic authentication, these settings provide the username and password that the Kibana server uses to perform maintenance on the Kibana index at startup. Your Kibana users still need to authenticate with Elasticsearch, which is proxied through the Kibana server.

elasticsearch.tribe.ssl.certificate: and elasticsearch.tribe.ssl.key:
Optional settings that provide the paths to the PEM-format SSL certificate and key files. These files validate that your Elasticsearch backend uses the same key files.

elasticsearch.tribe.ssl.keyPassphrase
The passphrase that will be used to decrypt the private key. This value is optional as the key may not be encrypted.

elasticsearch.tribe.ssl.certificateAuthorities:
Optional setting that enables you to specify a path to the PEM file for the certificate authority for your tribe Elasticsearch instance.

elasticsearch.tribe.ssl.verificationMode:
Default: full Controls the verification of certificates. Valid values are none, certificate, and full. full performs hostname verification, and certificate does not.

elasticsearch.tribe.pingTimeout:
Default: the value of the elasticsearch.tribe.requestTimeout setting Time in milliseconds to wait for Elasticsearch to respond to pings.

elasticsearch.tribe.requestTimeout:
Default: 30000 Time in milliseconds to wait for responses from the back end or Elasticsearch. This value must be a positive integer.

elasticsearch.tribe.requestHeadersWhitelist:
Default: [ 'authorization' ] List of Kibana client-side headers to send to Elasticsearch. To send no client-side headers, set this value to [] (an empty list).

elasticsearch.tribe.customHeaders:
Default: {} Header names and values to send to Elasticsearch. Any custom headers cannot be overwritten by client-side headers, regardless of the elasticsearch.tribe.requestHeadersWhitelist configuration.

###########################################################################################################################

Networking in Compose
Estimated reading time: 5 minutes
Note: This document only applies if you’re using version 2 or higher of the Compose file format. Networking features are not supported for version 1 (legacy) Compose files.
By default Compose sets up a single network for your app. Each container for a service joins the default network and is both reachable by other containers on that network, and discoverable by them at a hostname identical to the container name.

Note: Your app’s network is given a name based on the “project name”, which is based on the name of the directory it lives in. You can override the project name with either the --project-name flag or the COMPOSE_PROJECT_NAME environment variable.
For example, suppose your app is in a directory called myapp, and your docker-compose.yml looks like this:

version: "3"
services:
  web:
    build: .
    ports:
      - "8000:8000"
  db:
    image: postgres
    ports:
      - "8001:5432"
When you run docker-compose up, the following happens:

A network called myapp_default is created.
A container is created using web’s configuration. It joins the network myapp_default under the name web.
A container is created using db’s configuration. It joins the network myapp_default under the name db.
Each container can now look up the hostname web or db and get back the appropriate container’s IP address. For example, web’s application code could connect to the URL postgres://db:5432 and start using the Postgres database.

It is important to note the distinction between HOST_PORT and CONTAINER_PORT. In the above example, for db, the HOST_PORT is 8001 and the container port is 5432 (postgres default). Networked service-to-service communication use the CONTAINER_PORT. When HOST_PORT is defined, the service is accessible outside the swarm as well.

Within the web container, your connection string to db would look like postgres://db:5432, and from the host machine, the connection string would look like postgres://{DOCKER_IP}:8001

###########################################################################################################################

docker-compose up
docker-compose down -> Data volumes will persist, so it’s possible to start the cluster again with the same data
docker-compose down -v -> To destroy the cluster and the data volumes just type
